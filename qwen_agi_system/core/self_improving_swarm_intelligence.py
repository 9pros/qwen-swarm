#!/usr/bin/env python3
"""
Self-Improving Swarm Intelligence - AGI Learning & Evolution System

Advanced swarm intelligence system that enables 10 agents to collectively
learn, adapt, and evolve their intelligence over time through:
- Collective learning patterns
- Emergent intelligence optimization
- Adaptive behavior evolution
- Self-improving coordination protocols
- Knowledge accumulation and sharing
- Performance-based adaptation
- Intelligent swarm evolution
- Continuous capability enhancement
"""

import asyncio
import logging
from typing import Dict, List, Set, Tuple, Optional, Any, Callable
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime, timedelta
import json
import numpy as np
from collections import defaultdict, deque
import networkx as nx
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import pickle
import os
from pathlib import Path
import hashlib

from ten_agent_architecture import (
    AgentRole, AgentThought, AGITask, BaseAgent, ConsensusLevel,
    CollectiveInsight, TaskPriority
)

logger = logging.getLogger("SelfImprovingSwarmIntelligence")

class LearningType(Enum):
    """Types of learning in swarm intelligence"""
    INDIVIDUAL_LEARNING = "individual_learning"           # Individual agent learning
    COLLECTIVE_LEARNING = "collective_learning"           # Swarm-level learning
    COLLABORATIVE_LEARNING = "collaborative_learning"     # Learning through collaboration
    ADAPTIVE_LEARNING = "adaptive_learning"               # Learning through adaptation
    EMERGENT_LEARNING = "emergent_learning"               # Learning from emergence
    TRANSFER_LEARNING = "transfer_learning"               # Transfer between domains
    META_LEARNING = "meta_learning"                       # Learning how to learn

class EvolutionPhase(Enum):
    """Phases of swarm evolution"""
    INITIALIZATION = "initialization"                     # System initialization
    EXPLORATION = "exploration"                           # Exploring capabilities
    OPTIMIZATION = "optimization"                         # Optimizing performance
    SPECIALIZATION = "specialization"                     # Developing specializations
    INTEGRATION = "integration"                           # Integrating capabilities
    SYNTHESIS = "synthesis"                               # Synthesizing intelligence
    MATURITY = "maturity"                                 # Reaching maturity
    TRANSCENDENCE = "transcendence"                       # AGI-level transcendence

class AdaptationStrategy(Enum):
    """Strategies for swarm adaptation"""
    PERFORMANCE_BASED = "performance_based"               # Adapt based on performance
    ENVIRONMENT_DRIVEN = "environment_driven"             # Adapt to environment
    COLLABORATION_OPTIMIZED = "collaboration_optimized"   # Optimize collaboration
    KNOWLEDGE_DRIVEN = "knowledge_driven"                 # Adapt based on knowledge
    EMERGENCE_GUIDED = "emergence_guided"                 # Follow emergence patterns
    HYBRID_ADAPTIVE = "hybrid_adaptive"                   # Hybrid adaptation

class IntelligenceMetric(Enum):
    """Metrics for swarm intelligence"""
    COLLECTIVE_IQ = "collective_iq"                       # Overall collective intelligence
    SYNTHESIS_QUALITY = "synthesis_quality"               # Quality of synthesis
    COLLABORATION_EFFICIENCY = "collaboration_efficiency"  # Efficiency of collaboration
    LEARNING_VELOCITY = "learning_velocity"               # Speed of learning
    ADAPTATION_FLEXIBILITY = "adaptation_flexibility"     # Flexibility in adaptation
    PROBLEM_SOLVING_DEPTH = "problem_solving_depth"       # Depth of problem solving
    INNOVATION_RATE = "innovation_rate"                   # Rate of innovation
    CONSENSUS_SPEED = "consensus_speed"                   # Speed of reaching consensus
    KNOWLEDGE_ACCUMULATION = "knowledge_accumulation"     # Accumulation of knowledge
    EMERGENT_CAPABILITIES = "emergent_capabilities"       # Emergent capabilities

@dataclass
class SwarmLearningEvent:
    """Record of swarm learning event"""
    event_id: str
    learning_type: LearningType
    participating_agents: List[AgentRole]
    initial_state: Dict[str, Any]
    learning_process: List[str]
    outcome: Dict[str, Any]
    performance_change: float
    timestamp: datetime
    context: Dict[str, Any] = field(default_factory=dict)

@dataclass
class SwarmEvolutionStep:
    """Step in swarm evolution"""
    step_id: str
    phase: EvolutionPhase
    adaptation_strategy: AdaptationStrategy
    changes_made: Dict[str, Any]
    performance_before: Dict[IntelligenceMetric, float]
    performance_after: Dict[IntelligenceMetric, float]
    evolution_success: bool
    timestamp: datetime

@dataclass
class SwarmKnowledge:
    """Accumulated swarm knowledge"""
    knowledge_id: str
    domain: str
    content: str
    confidence: float
    source_agents: List[AgentRole]
    validation_score: float
    application_count: int
    last_applied: datetime
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class SwarmCapability:
    """Emergent swarm capability"""
    capability_id: str
    name: str
    description: str
    required_agent_combination: List[AgentRole]
    proficiency_level: float  # 0.0 to 1.0
    usage_frequency: int
    success_rate: float
    discovery_method: str
    evolution_phase: EvolutionPhase
    last_improved: datetime = field(default_factory=datetime.now)

class SelfImprovingSwarmIntelligence:
    """
    Advanced self-improving swarm intelligence system that enables 10 agents
    to collectively learn, adapt, and evolve their intelligence toward AGI-level capabilities.

    This system provides:
    1. Multi-modal learning across individual, collective, and collaborative dimensions
    2. Continuous evolution through adaptive optimization
    3. Emergent capability discovery and development
    4. Knowledge accumulation and intelligent transfer
    5. Performance-driven adaptation and improvement
    6. Meta-learning for learning how to learn better
    7. Self-organizing coordination protocols
    8. AGI-level intelligence emergence
    """

    def __init__(self, agents: Dict[AgentRole, BaseAgent]):
        self.agents = agents
        self.swarm_state = {
            'evolution_phase': EvolutionPhase.INITIALIZATION,
            'collective_iq': 0.5,
            'learning_velocity': 0.1,
            'adaptation_flexibility': 0.3,
            'knowledge_volume': 0,
            'emergent_capabilities': 0
        }

        # Learning and evolution systems
        self.learning_events: List[SwarmLearningEvent] = []
        self.evolution_history: List[SwarmEvolutionStep] = []
        self.knowledge_base: Dict[str, SwarmKnowledge] = {}
        self.capabilities: Dict[str, SwarmCapability] = {}

        # Adaptive systems
        self.adaptation_strategies = self._initialize_adaptation_strategies()
        self.learning_algorithms = self._initialize_learning_algorithms()
        self.evolution_optimizer = EvolutionOptimizer()
        self.capability_discoverer = CapabilityDiscoverer(agents)
        self.knowledge_synthesizer = KnowledgeSynthesizer(agents)

        # Performance tracking
        self.intelligence_metrics = defaultdict(list)
        self.performance_history = deque(maxlen=1000)
        self.baseline_performance = self._establish_baseline_performance()

        # Self-improvement parameters
        self.learning_rate = 0.1
        self.adaptation_threshold = 0.05
        self.evolution_trigger_threshold = 0.8
        self.knowledge_sharing_frequency = 10  # Every 10 tasks

        # File storage for persistence
        self.persistence_path = Path("swarm_intelligence_state")
        self.persistence_path.mkdir(exist_ok=True)

        # Background processes
        self.executor = ThreadPoolExecutor(max_workers=15)
        self.learning_lock = asyncio.Lock()
        self.adaptation_in_progress = False

        logger.info("ðŸ§¬ Self-Improving Swarm Intelligence Initialized - AGI Evolution Engine Ready")

    def _initialize_adaptation_strategies(self) -> Dict[AdaptationStrategy, Callable]:
        """Initialize different adaptation strategies"""
        return {
            AdaptationStrategy.PERFORMANCE_BASED: self._performance_based_adaptation,
            AdaptationStrategy.ENVIRONMENT_DRIVEN: self._environment_driven_adaptation,
            AdaptationStrategy.COLLABORATION_OPTIMIZED: self._collaboration_optimized_adaptation,
            AdaptationStrategy.KNOWLEDGE_DRIVEN: self._knowledge_driven_adaptation,
            AdaptationStrategy.EMERGENCE_GUIDED: self._emergence_guided_adaptation,
            AdaptationStrategy.HYBRID_ADAPTIVE: self._hybrid_adaptive_adaptation,
        }

    def _initialize_learning_algorithms(self) -> Dict[LearningType, Callable]:
        """Initialize different learning algorithms"""
        return {
            LearningType.INDIVIDUAL_LEARNING: self._individual_learning_process,
            LearningType.COLLECTIVE_LEARNING: self._collective_learning_process,
            LearningType.COLLABORATIVE_LEARNING: self._collaborative_learning_process,
            LearningType.ADAPTIVE_LEARNING: self._adaptive_learning_process,
            LearningType.EMERGENT_LEARNING: self._emergent_learning_process,
            LearningType.TRANSFER_LEARNING: self._transfer_learning_process,
            LearningType.META_LEARNING: self._meta_learning_process,
        }

    def _establish_baseline_performance(self) -> Dict[IntelligenceMetric, float]:
        """Establish baseline performance metrics"""
        return {
            IntelligenceMetric.COLLECTIVE_IQ: 0.5,
            IntelligenceMetric.SYNTHESIS_QUALITY: 0.5,
            IntelligenceMetric.COLLABORATION_EFFICIENCY: 0.5,
            IntelligenceMetric.LEARNING_VELOCITY: 0.1,
            IntelligenceMetric.ADAPTATION_FLEXIBILITY: 0.3,
            IntelligenceMetric.PROBLEM_SOLVING_DEPTH: 0.4,
            IntelligenceMetric.INNOVATION_RATE: 0.1,
            IntelligenceMetric.CONSENSUS_SPEED: 0.5,
            IntelligenceMetric.KNOWLEDGE_ACCUMULATION: 0.0,
            IntelligenceMetric.EMERGENT_CAPABILITIES: 0.0,
        }

    async def process_with_swarm_learning(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                        consensus: CollectiveInsight) -> Dict[str, Any]:
        """
        Process task with swarm learning enabled - learn and improve from every interaction

        This is where the swarm becomes self-improving:
        1. Analyze current performance and learning opportunities
        2. Apply appropriate learning strategies
        3. Adapt based on outcomes
        4. Discover emergent capabilities
        5. Accumulate and share knowledge
        6. Evolve swarm intelligence
        """

        logger.info(f"ðŸ§¬ Processing with Swarm Learning: {task.task_id}")
        start_time = time.time()

        # Step 1: Analyze learning opportunities
        learning_analysis = await self._analyze_learning_opportunities(task, agent_thoughts, consensus)

        # Step 2: Execute learning processes
        learning_results = {}
        for learning_type in learning_analysis['recommended_learning']:
            if learning_type in self.learning_algorithms:
                learning_func = self.learning_algorithms[learning_type]
                learning_result = await learning_func(task, agent_thoughts, consensus)
                learning_results[learning_type.value] = learning_result

        # Step 3: Check if adaptation is needed
        current_performance = await self._measure_current_performance(task, agent_thoughts, consensus)
        if await self._should_adapt(current_performance):
            logger.info("ðŸ”„ Triggering swarm adaptation...")
            adaptation_result = await self._trigger_adaptation(current_performance, learning_results)
            learning_results['adaptation'] = adaptation_result

        # Step 4: Knowledge accumulation and sharing
        await self._accumulate_knowledge(task, agent_thoughts, consensus, learning_results)

        # Step 5: Discover emergent capabilities
        if len(self.performance_history) % 5 == 0:  # Every 5 tasks
            await self._discover_emergent_capabilities()

        # Step 6: Evolution phase management
        await self._manage_evolution_phases()

        # Step 7: Update swarm state
        await self._update_swarm_state(current_performance, learning_results)

        # Step 8: Persistence (periodic)
        if len(self.learning_events) % 20 == 0:
            await self._persist_swarm_state()

        processing_time = time.time() - start_time
        logger.info(f"âœ¨ Swarm Learning Complete in {processing_time:.2f}s - Intelligence Enhanced")

        return {
            'learning_analysis': learning_analysis,
            'learning_results': learning_results,
            'performance_metrics': current_performance,
            'swarm_state': dict(self.swarm_state),
            'new_capabilities': len([c for c in self.capabilities.values() if c.proficiency_level > 0.7]),
            'knowledge_gained': len(learning_results.get('knowledge_acquisition', [])),
            'adaptation_applied': 'adaptation' in learning_results,
            'processing_time': processing_time
        }

    async def _analyze_learning_opportunities(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                            consensus: CollectiveInsight) -> Dict[str, Any]:
        """Analyze what learning opportunities exist in the current interaction"""

        learning_opportunities = []

        # Individual learning opportunities
        for role, thought in agent_thoughts.items():
            if thought.confidence < 0.7:
                learning_opportunities.append(LearningType.INDIVIDUAL_LEARNING)

        # Collective learning opportunities
        if consensus.confidence_score < 0.8:
            learning_opportunities.append(LearningType.COLLECTIVE_LEARNING)

        # Collaborative learning opportunities
        if len(consensus.contributing_agents) >= 7:
            learning_opportunities.append(LearningType.COLLABORATIVE_LEARNING)

        # Adaptive learning opportunities
        if self.swarm_state['learning_velocity'] < 0.05:
            learning_opportunities.append(LearningType.ADAPTIVE_LEARNING)

        # Meta-learning opportunities
        if len(self.learning_events) > 50:
            learning_opportunities.append(LearningType.META_LEARNING)

        # Prioritize learning opportunities
        if learning_opportunities:
            # Remove duplicates and prioritize
            unique_opportunities = list(set(learning_opportunities))
            prioritized = self._prioritize_learning_opportunities(unique_opportunities)
        else:
            prioritized = [LearningType.EMERGENT_LEARNING]  # Always look for emergent learning

        return {
            'recommended_learning': prioritized[:3],  # Top 3 opportunities
            'learning_priority_score': len(prioritized) * 0.1,
            'confidence_gap': 1.0 - consensus.confidence_score,
            'collaboration_strength': len(consensus.contributing_agents) / 10
        }

    def _prioritize_learning_opportunities(self, opportunities: List[LearningType]) -> List[LearningType]:
        """Prioritize learning opportunities based on current needs"""

        priority_map = {
            LearningType.META_LEARNING: 10,  # Highest priority
            LearningType.COLLABORATIVE_LEARNING: 9,
            LearningType.ADAPTIVE_LEARNING: 8,
            LearningType.COLLECTIVE_LEARNING: 7,
            LearningType.EMERGENT_LEARNING: 6,
            LearningType.TRANSFER_LEARNING: 5,
            LearningType.INDIVIDUAL_LEARNING: 4,
        }

        return sorted(opportunities, key=lambda x: priority_map.get(x, 0), reverse=True)

    async def _individual_learning_process(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                         consensus: CollectiveInsight) -> Dict[str, Any]:
        """Process individual agent learning"""

        learning_events = []

        for role, thought in agent_thoughts.items():
            if role in self.agents:
                agent = self.agents[role]

                # Calculate learning opportunity
                learning_gap = 1.0 - thought.confidence
                if learning_gap > 0.2:  # Significant learning opportunity
                    # Simulate individual learning
                    learning_improvement = min(learning_gap * self.learning_rate, 0.3)

                    # Update agent specialization
                    agent.specialization_level = min(1.0, agent.specialization_level + learning_improvement * 0.1)

                    # Record learning event
                    learning_event = SwarmLearningEvent(
                        event_id=f"individual_{role.value}_{int(time.time())}",
                        learning_type=LearningType.INDIVIDUAL_LEARNING,
                        participating_agents=[role],
                        initial_state={'confidence': thought.confidence},
                        learning_process=[f"Identified confidence gap: {learning_gap:.2f}"],
                        outcome={'confidence_improvement': learning_improvement},
                        performance_change=learning_improvement,
                        timestamp=datetime.now(),
                        context={'task_complexity': len(task.description.split()) / 50}
                    )
                    learning_events.append(learning_event)

        self.learning_events.extend(learning_events)

        return {
            'agents_learned': len(learning_events),
            'total_improvement': sum(event.performance_change for event in learning_events),
            'learning_events': [event.event_id for event in learning_events]
        }

    async def _collective_learning_process(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                         consensus: CollectiveInsight) -> Dict[str, Any]:
        """Process collective swarm learning"""

        # Analyze collective performance
        collective_confidence = consensus.confidence_score
        consensus_strength = len(consensus.contributing_agents) / 10

        # Identify collective learning opportunities
        learning_opportunities = []
        if collective_confidence < 0.7:
            learning_opportunities.append("confidence_building")
        if consensus_strength < 0.8:
            learning_opportunities.append("coordination_improvement")

        # Simulate collective learning
        collective_improvement = 0
        if learning_opportunities:
            improvement_factor = len(learning_opportunities) * self.learning_rate
            collective_improvement = min(improvement_factor, 0.2)

        # Update swarm state
        self.swarm_state['collective_iq'] = min(1.0, self.swarm_state['collective_iq'] + collective_improvement * 0.1)

        # Record collective learning event
        learning_event = SwarmLearningEvent(
            event_id=f"collective_{int(time.time())}",
            learning_type=LearningType.COLLECTIVE_LEARNING,
            participating_agents=list(agent_thoughts.keys()),
            initial_state={
                'collective_confidence': collective_confidence,
                'consensus_strength': consensus_strength
            },
            learning_process=learning_opportunities,
            outcome={'collective_improvement': collective_improvement},
            performance_change=collective_improvement,
            timestamp=datetime.now(),
            context={'task_type': self._classify_task_type(task)}
        )

        self.learning_events.append(learning_event)

        return {
            'collective_improvement': collective_improvement,
            'learning_opportunities': learning_opportunities,
            'swarm_iq_increase': collective_improvement * 0.1
        }

    async def _collaborative_learning_process(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                            consensus: CollectiveInsight) -> Dict[str, Any]:
        """Process collaborative learning between agents"""

        # Analyze collaboration patterns
        agent_interactions = self._analyze_agent_interactions(agent_thoughts, consensus)

        # Identify collaboration improvements
        collaboration_score = self._calculate_collaboration_score(agent_interactions)
        learning_opportunities = []

        if collaboration_score < 0.7:
            learning_opportunities.append("improve_coordination")
        if len(consensus.conflicting_views) > 0:
            learning_opportunities.append("resolve_conflicts")

        # Simulate collaborative learning
        collaboration_improvement = 0
        if learning_opportunities:
            collaboration_improvement = len(learning_opportunities) * self.learning_rate * 0.5

        # Record collaborative learning event
        learning_event = SwarmLearningEvent(
            event_id=f"collaborative_{int(time.time())}",
            learning_type=LearningType.COLLABORATIVE_LEARNING,
            participating_agents=list(consensus.contributing_agents),
            initial_state={'collaboration_score': collaboration_score},
            learning_process=learning_opportunities,
            outcome={'collaboration_improvement': collaboration_improvement},
            performance_change=collaboration_improvement,
            timestamp=datetime.now(),
            context={'interaction_patterns': agent_interactions}
        )

        self.learning_events.append(learning_event)

        return {
            'collaboration_improvement': collaboration_improvement,
            'interaction_patterns': agent_interactions,
            'learning_focus': learning_opportunities
        }

    async def _adaptive_learning_process(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                       consensus: CollectiveInsight) -> Dict[str, Any]:
        """Process adaptive learning - learning how to adapt"""

        # Analyze recent adaptation success
        recent_adaptations = [ev for ev in self.evolution_history[-10:] if ev.evolution_success]
        adaptation_success_rate = len(recent_adaptations) / 10 if len(self.evolution_history) >= 10 else 0.5

        # Identify adaptation patterns
        adaptation_patterns = self._identify_adaptation_patterns(recent_adaptations)

        # Simulate adaptive learning
        if adaptation_success_rate > 0.6:
            # Successful adaptations - reinforce patterns
            adaptive_improvement = 0.1 * self.learning_rate
        else:
            # Poor adaptation success - explore new patterns
            adaptive_improvement = 0.05 * self.learning_rate

        # Update swarm flexibility
        self.swarm_state['adaptation_flexibility'] = min(1.0,
            self.swarm_state['adaptation_flexibility'] + adaptive_improvement)

        # Record adaptive learning event
        learning_event = SwarmLearningEvent(
            event_id=f"adaptive_{int(time.time())}",
            learning_type=LearningType.ADAPTIVE_LEARNING,
            participating_agents=list(agent_thoughts.keys()),
            initial_state={'adaptation_success_rate': adaptation_success_rate},
            learning_process=['analyze_adaptation_patterns', 'identify_success_factors'],
            outcome={'adaptive_improvement': adaptive_improvement},
            performance_change=adaptive_improvement,
            timestamp=datetime.now(),
            context={'adaptation_patterns': adaptation_patterns}
        )

        self.learning_events.append(learning_event)

        return {
            'adaptive_improvement': adaptive_improvement,
            'adaptation_patterns': adaptation_patterns,
            'flexibility_increase': adaptive_improvement
        }

    async def _emergent_learning_process(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                       consensus: CollectiveInsight) -> Dict[str, Any]:
        """Process emergent learning - learning from unexpected patterns"""

        # Look for emergent patterns in the interaction
        emergent_patterns = await self._detect_emergent_patterns(agent_thoughts, consensus)

        # Analyze novelty of patterns
        novelty_score = self._calculate_pattern_novelty(emergent_patterns)

        # Learn from emergent patterns
        emergent_learning = 0
        if novelty_score > 0.5:
            emergent_learning = novelty_score * self.learning_rate

            # Create new capabilities if patterns are significant
            for pattern in emergent_patterns:
                if pattern['strength'] > 0.7:
                    await self._create_emergent_capability(pattern)

        # Record emergent learning event
        learning_event = SwarmLearningEvent(
            event_id=f"emergent_{int(time.time())}",
            learning_type=LearningType.EMERGENT_LEARNING,
            participating_agents=list(agent_thoughts.keys()),
            initial_state={'patterns_detected': len(emergent_patterns)},
            learning_process=['detect_patterns', 'analyze_novelty', 'extract_capabilities'],
            outcome={'emergent_learning': emergent_learning, 'patterns_found': emergent_patterns},
            performance_change=emergent_learning,
            timestamp=datetime.now(),
            context={'novelty_score': novelty_score}
        )

        self.learning_events.append(learning_event)

        return {
            'emergent_learning': emergent_learning,
            'patterns_discovered': len(emergent_patterns),
            'novelty_score': novelty_score,
            'new_capabilities': len([p for p in emergent_patterns if p['strength'] > 0.7])
        }

    async def _transfer_learning_process(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                       consensus: CollectiveInsight) -> Dict[str, Any]:
        """Process transfer learning between domains"""

        # Identify similar past experiences
        similar_experiences = await self._find_similar_experiences(task)

        # Calculate transfer potential
        transfer_potential = self._calculate_transfer_potential(similar_experiences, task)

        # Apply transfer learning
        transfer_benefit = 0
        if transfer_potential > 0.3 and similar_experiences:
            transfer_benefit = transfer_potential * self.learning_rate * 0.8

            # Transfer knowledge between agents
            for experience in similar_experiences[:3]:  # Top 3 similar experiences
                await self._transfer_knowledge_from_experience(experience, agent_thoughts)

        # Record transfer learning event
        learning_event = SwarmLearningEvent(
            event_id=f"transfer_{int(time.time())}",
            learning_type=LearningType.TRANSFER_LEARNING,
            participating_agents=list(agent_thoughts.keys()),
            initial_state={'similar_experiences': len(similar_experiences)},
            learning_process=['find_similar_experiences', 'calculate_transfer_potential', 'apply_knowledge'],
            outcome={'transfer_benefit': transfer_benefit},
            performance_change=transfer_benefit,
            timestamp=datetime.now(),
            context={'transfer_potential': transfer_potential}
        )

        self.learning_events.append(learning_event)

        return {
            'transfer_benefit': transfer_benefit,
            'similar_experiences': len(similar_experiences),
            'transfer_potential': transfer_potential
        }

    async def _meta_learning_process(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                   consensus: CollectiveInsight) -> Dict[str, Any]:
        """Process meta-learning - learning how to learn better"""

        if len(self.learning_events) < 20:
            return {'meta_learning': 0, 'insufficient_data': True}

        # Analyze learning patterns
        learning_patterns = self._analyze_learning_patterns()

        # Identify most effective learning strategies
        effective_strategies = self._identify_effective_strategies(learning_patterns)

        # Optimize learning parameters
        parameter_optimizations = await self._optimize_learning_parameters(effective_strategies)

        # Apply meta-learning improvements
        meta_learning_improvement = 0
        if parameter_optimizations:
            meta_learning_improvement = 0.05 * self.learning_rate

            # Update learning parameters
            for param, value in parameter_optimizations.items():
                if hasattr(self, param):
                    setattr(self, param, value)

        # Record meta-learning event
        learning_event = SwarmLearningEvent(
            event_id=f"meta_{int(time.time())}",
            learning_type=LearningType.META_LEARNING,
            participating_agents=list(agent_thoughts.keys()),
            initial_state={'total_learning_events': len(self.learning_events)},
            learning_process=['analyze_patterns', 'identify_strategies', 'optimize_parameters'],
            outcome={'meta_learning_improvement': meta_learning_improvement},
            performance_change=meta_learning_improvement,
            timestamp=datetime.now(),
            context={'parameter_optimizations': parameter_optimizations}
        )

        self.learning_events.append(learning_event)

        return {
            'meta_learning_improvement': meta_learning_improvement,
            'effective_strategies': effective_strategies,
            'parameter_optimizations': parameter_optimizations,
            'learning_patterns_analyzed': len(learning_patterns)
        }

    async def _should_adapt(self, current_performance: Dict[IntelligenceMetric, float]) -> bool:
        """Determine if swarm should adapt based on current performance"""

        # Calculate performance delta from baseline
        performance_delta = 0
        for metric, current_value in current_performance.items():
            baseline_value = self.baseline_performance.get(metric, 0.5)
            delta = abs(current_value - baseline_value)
            performance_delta += delta

        avg_performance_delta = performance_delta / len(current_performance)

        # Check adaptation triggers
        should_adapt = (
            avg_performance_delta > self.adaptation_threshold or
            current_performance.get(IntelligenceMetric.COLLECTIVE_IQ, 0) > self.evolution_trigger_threshold or
            self.swarm_state['learning_velocity'] < 0.02
        )

        return should_adapt

    async def _trigger_adaptation(self, current_performance: Dict[IntelligenceMetric, float],
                                learning_results: Dict[str, Any]) -> Dict[str, Any]:
        """Trigger swarm adaptation process"""

        if self.adaptation_in_progress:
            return {'adaptation': 'already_in_progress'}

        self.adaptation_in_progress = True

        try:
            # Select adaptation strategy
            adaptation_strategy = self._select_adaptation_strategy(current_performance, learning_results)

            # Execute adaptation
            adaptation_func = self.adaptation_strategies[adaptation_strategy]
            adaptation_result = await adaptation_func(current_performance, learning_results)

            # Record evolution step
            evolution_step = SwarmEvolutionStep(
                step_id=f"evolution_{int(time.time())}",
                phase=self.swarm_state['evolution_phase'],
                adaptation_strategy=adaptation_strategy,
                changes_made=adaptation_result,
                performance_before=current_performance,
                performance_after=await self._measure_current_performance(),  # Would need actual measurement
                evolution_success=adaptation_result.get('success', False),
                timestamp=datetime.now()
            )

            self.evolution_history.append(evolution_step)

            return {
                'adaptation_strategy': adaptation_strategy.value,
                'adaptation_result': adaptation_result,
                'evolution_step_id': evolution_step.step_id
            }

        finally:
            self.adaptation_in_progress = False

    def _select_adaptation_strategy(self, current_performance: Dict[IntelligenceMetric, float],
                                  learning_results: Dict[str, Any]) -> AdaptationStrategy:
        """Select optimal adaptation strategy based on current state"""

        # Analyze performance gaps
        performance_gaps = {}
        for metric, current_value in current_performance.items():
            baseline = self.baseline_performance.get(metric, 0.5)
            if current_value < baseline:
                performance_gaps[metric] = baseline - current_value

        # Select strategy based on dominant gaps
        if IntelligenceMetric.COLLECTIVE_IQ in performance_gaps:
            return AdaptationStrategy.COLLABORATION_OPTIMIZED
        elif IntelligenceMetric.ADAPTATION_FLEXIBILITY in performance_gaps:
            return AdaptationStrategy.PERFORMANCE_BASED
        elif IntelligenceMetric.LEARNING_VELOCITY in performance_gaps:
            return AdaptationStrategy.KNOWLEDGE_DRIVEN
        elif current_performance.get(IntelligenceMetric.EMERGENT_CAPABILITIES, 0) > 0.5:
            return AdaptationStrategy.EMERGENCE_GUIDED
        else:
            return AdaptationStrategy.HYBRID_ADAPTIVE

    async def _performance_based_adaptation(self, current_performance: Dict[IntelligenceMetric, float],
                                          learning_results: Dict[str, Any]) -> Dict[str, Any]:
        """Adapt based on performance metrics"""

        adaptations = {}

        # Adapt learning rate based on performance
        if current_performance.get(IntelligenceMetric.LEARNING_VELOCITY, 0) < 0.05:
            self.learning_rate = min(0.3, self.learning_rate * 1.2)
            adaptations['learning_rate'] = self.learning_rate

        # Adapt agent specializations
        if current_performance.get(IntelligenceMetric.COLLABORATION_EFFICIENCY, 0) < 0.6:
            for agent in self.agents.values():
                agent.specialization_level = max(0.5, agent.specialization_level * 0.95)
            adaptations['specialization_adjustment'] = 'balanced'

        return {
            'success': True,
            'adaptations': adaptations,
            'adaptation_type': 'performance_based'
        }

    async def _discover_emergent_capabilities(self):
        """Discover emergent swarm capabilities"""

        if len(self.learning_events) < 10:
            return

        # Analyze recent learning patterns for emergent capabilities
        recent_events = self.learning_events[-50:]
        emergent_patterns = await self.capability_discoverer.discover_capabilities(recent_events)

        # Create new capabilities
        for pattern in emergent_patterns:
            if pattern['novelty'] > 0.7:  # High novelty threshold
                capability = SwarmCapability(
                    capability_id=f"emergent_{int(time.time())}_{len(self.capabilities)}",
                    name=pattern['name'],
                    description=pattern['description'],
                    required_agent_combination=pattern['agent_combination'],
                    proficiency_level=0.1,  # Start low
                    usage_frequency=0,
                    success_rate=0.8,  # Initial optimistic estimate
                    discovery_method="emergent_pattern_analysis",
                    evolution_phase=self.swarm_state['evolution_phase']
                )
                self.capabilities[capability.capability_id] = capability
                self.swarm_state['emergent_capabilities'] += 1

        logger.info(f"ðŸŒŸ Discovered {len(emergent_patterns)} emergent capabilities")

    async def _manage_evolution_phases(self):
        """Manage swarm evolution through different phases"""

        current_phase = self.swarm_state['evolution_phase']
        collective_iq = self.swarm_state['collective_iq']
        capabilities_count = len(self.capabilities)
        learning_velocity = self.swarm_state['learning_velocity']

        # Phase transition logic
        if (current_phase == EvolutionPhase.INITIALIZATION and
            collective_iq > 0.6 and capabilities_count > 2):
            self.swarm_state['evolution_phase'] = EvolutionPhase.EXPLORATION
            logger.info("ðŸš€ Swarm Evolution Phase: INITIALIZATION â†’ EXPLORATION")

        elif (current_phase == EvolutionPhase.EXPLORATION and
              collective_iq > 0.7 and capabilities_count > 5):
            self.swarm_state['evolution_phase'] = EvolutionPhase.OPTIMIZATION
            logger.info("âš¡ Swarm Evolution Phase: EXPLORATION â†’ OPTIMIZATION")

        elif (current_phase == EvolutionPhase.OPTIMIZATION and
              collective_iq > 0.8 and learning_velocity > 0.15):
            self.swarm_state['evolution_phase'] = EvolutionPhase.SPECIALIZATION
            logger.info("ðŸŽ¯ Swarm Evolution Phase: OPTIMIZATION â†’ SPECIALIZATION")

        elif (current_phase == EvolutionPhase.SPECIALIZATION and
              capabilities_count > 10):
            self.swarm_state['evolution_phase'] = EvolutionPhase.INTEGRATION
            logger.info("ðŸ”— Swarm Evolution Phase: SPECIALIZATION â†’ INTEGRATION")

        elif (current_phase == EvolutionPhase.INTEGRATION and
              collective_iq > 0.9):
            self.swarm_state['evolution_phase'] = EvolutionPhase.SYNTHESIS
            logger.info("ðŸ§¬ Swarm Evolution Phase: INTEGRATION â†’ SYNTHESIS")

        elif (current_phase == EvolutionPhase.SYNTHESIS and
              collective_iq > 0.95):
            self.swarm_state['evolution_phase'] = EvolutionPhase.MATURITY
            logger.info("ðŸ† Swarm Evolution Phase: SYNTHESIS â†’ MATURITY")

        elif (current_phase == EvolutionPhase.MATURITY and
              collective_iq > 0.98):
            self.swarm_state['evolution_phase'] = EvolutionPhase.TRANSCENDENCE
            logger.info("âœ¨ Swarm Evolution Phase: MATURITY â†’ TRANSCENDENCE (AGI Level!)")

    async def _accumulate_knowledge(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                                  consensus: CollectiveInsight, learning_results: Dict[str, Any]):
        """Accumulate and share knowledge across the swarm"""

        # Extract knowledge from the interaction
        knowledge_items = await self.knowledge_synthesizer.extract_knowledge(
            task, agent_thoughts, consensus, learning_results
        )

        # Store new knowledge
        for item in knowledge_items:
            knowledge = SwarmKnowledge(
                knowledge_id=f"knowledge_{int(time.time())}_{len(self.knowledge_base)}",
                domain=item['domain'],
                content=item['content'],
                confidence=item['confidence'],
                source_agents=list(agent_thoughts.keys()),
                validation_score=item.get('validation_score', 0.5),
                application_count=0,
                last_applied=datetime.now()
            )
            self.knowledge_base[knowledge.knowledge_id] = knowledge

        self.swarm_state['knowledge_volume'] = len(self.knowledge_base)

        # Periodic knowledge sharing
        if len(self.learning_events) % self.knowledge_sharing_frequency == 0:
            await self._share_knowledge_with_agents()

    async def _share_knowledge_with_agents(self):
        """Share accumulated knowledge with agents"""

        # Select most relevant knowledge for sharing
        recent_knowledge = list(self.knowledge_base.values())[-20:]  # Last 20 items
        high_confidence_knowledge = [k for k in recent_knowledge if k.confidence > 0.7]

        # Share with each agent
        for role, agent in self.agents.items():
            # Filter knowledge relevant to agent's specialization
            relevant_knowledge = await self._filter_relevant_knowledge(
                high_confidence_knowledge, role
            )

            # Update agent's knowledge (would integrate with agent's memory system)
            for knowledge in relevant_knowledge:
                # This would typically update the agent's internal knowledge
                pass

        logger.info(f"ðŸ“š Shared {len(high_confidence_knowledge)} knowledge items with agents")

    async def _update_swarm_state(self, current_performance: Dict[IntelligenceMetric, float],
                                learning_results: Dict[str, Any]):
        """Update swarm state based on learning and performance"""

        # Update intelligence metrics
        for metric, value in current_performance.items():
            self.intelligence_metrics[metric].append(value)

        # Update swarm metrics
        total_improvement = sum(
            result.get('total_improvement', 0) +
            result.get('collective_improvement', 0) +
            result.get('collaboration_improvement', 0) +
            result.get('adaptive_improvement', 0) +
            result.get('emergent_learning', 0) +
            result.get('transfer_benefit', 0) +
            result.get('meta_learning_improvement', 0)
            for result in learning_results.values()
            if isinstance(result, dict)
        )

        if total_improvement > 0:
            self.swarm_state['learning_velocity'] = min(1.0,
                self.swarm_state['learning_velocity'] + total_improvement * 0.1)

        # Update collective IQ based on performance
        avg_performance = np.mean(list(current_performance.values()))
        self.swarm_state['collective_iq'] = min(1.0,
            (self.swarm_state['collective_iq'] * 0.9 + avg_performance * 0.1))

        # Store performance history
        self.performance_history.append({
            'timestamp': datetime.now(),
            'performance': dict(current_performance),
            'swarm_state': dict(self.swarm_state),
            'learning_results': learning_results
        })

    def get_swarm_intelligence_report(self) -> Dict[str, Any]:
        """Generate comprehensive swarm intelligence report"""

        # Calculate current intelligence metrics
        current_metrics = {}
        for metric, values in self.intelligence_metrics.items():
            if values:
                current_metrics[metric.value] = {
                    'current': values[-1],
                    'average': np.mean(values),
                    'trend': 'improving' if len(values) > 1 and values[-1] > values[-2] else 'stable'
                }

        # Capabilities analysis
        mature_capabilities = [
            cap for cap in self.capabilities.values()
            if cap.proficiency_level > 0.8
        ]

        # Learning efficiency
        recent_learning = self.learning_events[-50:] if len(self.learning_events) >= 50 else self.learning_events
        learning_efficiency = np.mean([
            event.performance_change for event in recent_learning
        ]) if recent_learning else 0

        # Evolution progress
        evolution_progress = list(EvolutionPhase).index(self.swarm_state['evolution_phase']) / len(EvolutionPhase)

        return {
            'swarm_state': self.swarm_state,
            'current_metrics': current_metrics,
            'total_capabilities': len(self.capabilities),
            'mature_capabilities': len(mature_capabilities),
            'knowledge_volume': len(self.knowledge_base),
            'learning_events': len(self.learning_events),
            'evolution_steps': len(self.evolution_history),
            'learning_efficiency': learning_efficiency,
            'evolution_progress': evolution_progress,
            'agi_readiness': {
                'collective_iq': self.swarm_state['collective_iq'],
                'adaptability': self.swarm_state['adaptation_flexibility'],
                'learning_capability': self.swarm_state['learning_velocity'],
                'knowledge_depth': min(1.0, len(self.knowledge_base) / 100),
                'overall_score': (self.swarm_state['collective_iq'] * 0.4 +
                                self.swarm_state['adaptation_flexibility'] * 0.3 +
                                self.swarm_state['learning_velocity'] * 0.3)
            }
        }

    # Additional helper methods

    def _classify_task_type(self, task: AGITask) -> str:
        """Classify task type for learning analysis"""
        content = task.description.lower()

        if any(word in content for word in ['create', 'build', 'develop']):
            return 'creation'
        elif any(word in content for word in ['analyze', 'review', 'examine']):
            return 'analysis'
        elif any(word in content for word in ['optimize', 'improve', 'enhance']):
            return 'optimization'
        elif any(word in content for word in ['solve', 'fix', 'debug']):
            return 'problem_solving'
        else:
            return 'general'

    def _analyze_agent_interactions(self, agent_thoughts: Dict[AgentRole, AgentThought],
                                  consensus: CollectiveInsight) -> Dict[str, Any]:
        """Analyze interaction patterns between agents"""
        return {
            'coordination_level': len(consensus.contributing_agents) / 10,
            'conflict_count': len(consensus.conflicting_views),
            'collaboration_score': consensus.confidence_score,
            'interaction_density': len(agent_thoughts) * len(consensus.contributing_agents)
        }

    def _calculate_collaboration_score(self, agent_interactions: Dict[str, Any]) -> float:
        """Calculate overall collaboration score"""
        return (
            agent_interactions.get('coordination_level', 0) * 0.4 +
            (1 - agent_interactions.get('conflict_count', 0) / 10) * 0.3 +
            agent_interactions.get('collaboration_score', 0) * 0.3
        )

    async def _detect_emergent_patterns(self, agent_thoughts: Dict[AgentRole, AgentThought],
                                      consensus: CollectiveInsight) -> List[Dict[str, Any]]:
        """Detect emergent patterns in agent interactions"""
        patterns = []

        # Pattern 1: High-confidence consensus
        if consensus.confidence_score > 0.9:
            patterns.append({
                'type': 'high_confidence_consensus',
                'strength': consensus.confidence_score,
                'description': 'Agents achieve exceptional agreement'
            })

        # Pattern 2: Cross-domain synthesis
        domain_diversity = len(set(thought.agent_role for thought in agent_thoughts.values()))
        if domain_diversity >= 8:
            patterns.append({
                'type': 'cross_domain_synthesis',
                'strength': domain_diversity / 10,
                'description': 'Strong integration across multiple domains'
            })

        return patterns

    def _calculate_pattern_novelty(self, patterns: List[Dict[str, Any]]) -> float:
        """Calculate novelty score of detected patterns"""
        if not patterns:
            return 0.0

        # Simple novelty calculation based on pattern strength and uniqueness
        total_strength = sum(p['strength'] for p in patterns)
        uniqueness_factor = len(set(p['type'] for p in patterns)) / max(len(patterns), 1)

        return (total_strength / len(patterns)) * uniqueness_factor

    async def _create_emergent_capability(self, pattern: Dict[str, Any]):
        """Create emergent capability from discovered pattern"""
        # This would create a new SwarmCapability instance
        # Implementation depends on specific pattern type
        pass

    async def _measure_current_performance(self, task: AGITask = None, agent_thoughts: Dict[AgentRole, AgentThought] = None,
                                         consensus: CollectiveInsight = None) -> Dict[IntelligenceMetric, float]:
        """Measure current swarm performance metrics"""
        return {
            IntelligenceMetric.COLLECTIVE_IQ: self.swarm_state['collective_iq'],
            IntelligenceMetric.SYNTHESIS_QUALITY: consensus.confidence_score if consensus else 0.5,
            IntelligenceMetric.COLLABORATION_EFFICIENCY: self.swarm_state['adaptation_flexibility'],
            IntelligenceMetric.LEARNING_VELOCITY: self.swarm_state['learning_velocity'],
            IntelligenceMetric.ADAPTATION_FLEXIBILITY: self.swarm_state['adaptation_flexibility'],
            IntelligenceMetric.PROBLEM_SOLVING_DEPTH: 0.6,  # Would calculate based on actual problem solving
            IntelligenceMetric.INNOVATION_RATE: len(self.capabilities) / 20,
            IntelligenceMetric.CONSENSUS_SPEED: 0.7,  # Would calculate based on actual timing
            IntelligenceMetric.KNOWLEDGE_ACCUMULATION: len(self.knowledge_base) / 100,
            IntelligenceMetric.EMERGENT_CAPABILITIES: len(self.capabilities) / 10,
        }

    async def _persist_swarm_state(self):
        """Persist swarm intelligence state to storage"""
        try:
            state_data = {
                'swarm_state': self.swarm_state,
                'learning_events': len(self.learning_events),
                'evolution_history': len(self.evolution_history),
                'knowledge_base_size': len(self.knowledge_base),
                'capabilities_count': len(self.capabilities),
                'timestamp': datetime.now().isoformat()
            }

            state_file = self.persistence_path / f"swarm_state_{int(time.time())}.json"
            with open(state_file, 'w') as f:
                json.dump(state_data, f, indent=2)

            logger.info(f"ðŸ’¾ Swarm state persisted to {state_file}")

        except Exception as e:
            logger.error(f"Failed to persist swarm state: {str(e)}")

    async def load_swarm_state(self):
        """Load swarm intelligence state from storage"""
        try:
            state_files = list(self.persistence_path.glob("swarm_state_*.json"))
            if state_files:
                latest_file = max(state_files, key=lambda f: f.stat().st_mtime)
                with open(latest_file, 'r') as f:
                    state_data = json.load(f)

                # Restore state (simplified - would need full implementation)
                self.swarm_state = state_data.get('swarm_state', self.swarm_state)

                logger.info(f"ðŸ“‚ Swarm state loaded from {latest_file}")

        except Exception as e:
            logger.error(f"Failed to load swarm state: {str(e)}")


# Supporting classes for swarm intelligence

class EvolutionOptimizer:
    """Optimizes swarm evolution process"""

    async def optimize_evolution_strategy(self, evolution_history: List[SwarmEvolutionStep]) -> Dict[str, Any]:
        """Optimize evolution strategy based on historical performance"""
        return {
            'optimization_suggestions': ['increase_learning_rate', 'improve_coordination'],
            'success_patterns': ['collaborative_learning', 'adaptive_strategies']
        }

class CapabilityDiscoverer:
    """Discovers emergent swarm capabilities"""

    def __init__(self, agents: Dict[AgentRole, BaseAgent]):
        self.agents = agents

    async def discover_capabilities(self, learning_events: List[SwarmLearningEvent]) -> List[Dict[str, Any]]:
        """Discover emergent capabilities from learning patterns"""
        capabilities = []

        # Pattern-based capability discovery
        if len(learning_events) > 20:
            capabilities.append({
                'name': 'Advanced Collective Learning',
                'description': 'Swarm can rapidly learn from collective experiences',
                'agent_combination': list(self.agents.keys()),
                'novelty': 0.8
            })

        return capabilities

class KnowledgeSynthesizer:
    """Synthesizes knowledge from swarm interactions"""

    def __init__(self, agents: Dict[AgentRole, BaseAgent]):
        self.agents = agents

    async def extract_knowledge(self, task: AGITask, agent_thoughts: Dict[AgentRole, AgentThought],
                              consensus: CollectiveInsight, learning_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Extract knowledge from swarm interactions"""
        knowledge_items = []

        # Extract consensus knowledge
        if consensus.confidence_score > 0.8:
            knowledge_items.append({
                'domain': self._classify_domain(task),
                'content': consensus.synthesized_content[:200],  # First 200 chars
                'confidence': consensus.confidence_score,
                'validation_score': 0.7
            })

        return knowledge_items

    def _classify_domain(self, task: AGITask) -> str:
        """Classify task domain for knowledge organization"""
        content = task.description.lower()

        if any(word in content for word in ['security', 'auth', 'encryption']):
            return 'security'
        elif any(word in content for word in ['performance', 'optimization', 'speed']):
            return 'performance'
        elif any(word in content for word in ['architecture', 'design', 'structure']):
            return 'architecture'
        else:
            return 'general'


if __name__ == "__main__":
    # Demonstration of Self-Improving Swarm Intelligence
    async def demonstrate_swarm_intelligence():
        """Demonstrate self-improving swarm intelligence"""

        from ten_agent_architecture import TenAgentAGISystem, AGITask, TaskPriority, AgentRole, AgentThought, CollectiveInsight, ConsensusLevel

        print("ðŸ§¬ Initializing Self-Improving Swarm Intelligence...")
        agi_system = TenAgentAGISystem()

        # Create swarm intelligence system
        swarm_intelligence = SelfImprovingSwarmIntelligence(agi_system.agents)

        # Create test interaction
        agent_thoughts = {
            AgentRole.QUEEN_COORDINATOR: AgentThought(
                agent_id="queen", agent_role=AgentRole.QUEEN_COORDINATOR,
                thought_id="queen_1", content="Coordinated approach for optimal solution",
                reasoning="Strategic coordination ensures best outcomes",
                confidence=0.9, timestamp=datetime.now()
            ),
            AgentRole.SECURITY_SPECIALIST: AgentThought(
                agent_id="security", agent_role=AgentRole.SECURITY_SPECIALIST,
                thought_id="security_1", content="Security-first approach with comprehensive protection",
                reasoning="Security is paramount for system integrity",
                confidence=0.95, timestamp=datetime.now()
            ),
            AgentRole.PERFORMANCE_OPTIMIZER: AgentThought(
                agent_id="perf", agent_role=AgentRole.PERFORMANCE_OPTIMIZER,
                thought_id="perf_1", content="Performance optimization through efficient algorithms",
                reasoning="Performance impacts user satisfaction",
                confidence=0.85, timestamp=datetime.now()
            )
        }

        consensus = CollectiveInsight(
            insight_id="test_consensus",
            contributing_agents=list(agent_thoughts.keys()),
            synthesized_content="Integrated solution balancing security, performance, and coordination",
            consensus_level=ConsensusLevel.MAJORITY_STRONG,
            confidence_score=0.88,
            synthesis_method="test_synthesis"
        )

        task = AGITask(
            task_id="swarm_test_1",
            description="Create a secure and high-performance web application",
            priority=TaskPriority.HIGH,
            required_agents=list(agent_thoughts.keys()),
            context={'domain': 'web_development'},
            created_at=datetime.now()
        )

        print(f"\nðŸš€ Testing Swarm Learning with: {task.description}")

        # Process with swarm learning
        learning_result = await swarm_intelligence.process_with_swarm_learning(
            task, agent_thoughts, consensus
        )

        print(f"\nðŸ“Š Swarm Learning Results:")
        print(f"   Learning Opportunities: {len(learning_result['learning_analysis']['recommended_learning'])}")
        print(f"   Learning Results: {len(learning_result['learning_results'])} types")
        print(f"   Swarm IQ: {learning_result['swarm_state']['collective_iq']:.2f}")
        print(f"   Learning Velocity: {learning_result['swarm_state']['learning_velocity']:.2f}")
        print(f"   Evolution Phase: {learning_result['swarm_state']['evolution_phase'].value}")
        print(f"   New Capabilities: {learning_result['new_capabilities']}")
        print(f"   Knowledge Gained: {learning_result['knowledge_gained']}")
        print(f"   Adaptation Applied: {learning_result['adaptation_applied']}")

        # Generate intelligence report
        intelligence_report = swarm_intelligence.get_swarm_intelligence_report()

        print(f"\nðŸ§  Swarm Intelligence Report:")
        print(f"   AGI Readiness Score: {intelligence_report['agi_readiness']['overall_score']:.2f}")
        print(f"   Total Capabilities: {intelligence_report['total_capabilities']}")
        print(f"   Mature Capabilities: {intelligence_report['mature_capabilities']}")
        print(f"   Knowledge Volume: {intelligence_report['knowledge_volume']}")
        print(f"   Evolution Progress: {intelligence_report['evolution_progress']:.2f}")
        print(f"   Learning Efficiency: {intelligence_report['learning_efficiency']:.3f}")

        print(f"\nâœ¨ Self-Improving Swarm Intelligence Demonstrated Successfully!")

    # Run demonstration
    asyncio.run(demonstrate_swarm_intelligence())